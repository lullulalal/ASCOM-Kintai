{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lullulalal/ASCOM-Kintai/blob/master/exercise-12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5j5L51dZYuB"
      },
      "source": [
        "<div class=\"alert-block alert-info alert\"> Hello! If this is your first assignment please read the following instructions:\n",
        "\n",
        "Read the questions carefully and code what is asked in the respective code block whenever you see a ``` #TODO: YOUR CODE HERE. ```\n",
        "It is important to do the Coding tasks IN ORDER, as the majority of coding blocks are dependent on the\n",
        "previous coding blocks in the notebook.\n",
        "Please also note that there is a **raise NotImplementedError()** for each task or function you have to\n",
        "implement, so don't forget to remove it before testing your code, otherwise you will always get a \"not\n",
        "implemented\" error.\n",
        "\n",
        "You need to manually upload the data used in this exercise to Colab. Just create a folder 'data' and paste the respective files into this folder. Otherwise, you will get a 'File not found' error. You can find the data in StudOn.\n",
        "\n",
        "Aside from coding blocks, there are also testing blocks to check whether your implementations\n",
        "are correct, you can run them but do not change the code inside of them.\n",
        "The tests are determined via the ASSERT STATEMENTS that you see on the testing blocks, which can help you\n",
        "out during the coding of the exercises. If you pass all the visible asserts, you will probably get a good\n",
        "grade on the exercise, just remember that there are also hidden tests, so hardcoding the assert statements\n",
        "won't help you.\n",
        "\n",
        "REMEMBER: This Colab notebook DOES NOT HAVE AN AUTOSAVE FUNCTION, so whenever you want to close it, please\n",
        "remember to save it by clicking on the \"file\" tab in the upper left corner of the page, followed by\n",
        "clicking on the \"Save a copy to GitHub\" button and selecting your corresponding GitHub repository:\n",
        "\"madlab-biosig/exercise-x-YourGitHubUsername\"\n",
        "\n",
        "Before you save the final version of your assignment, please make sure everything runs as expected.\n",
        "First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all\n",
        "cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "VzCLZfWQZYuC"
      },
      "source": [
        "### BioSig Exercises WS 23/24\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJOhEcaNZYuC"
      },
      "source": [
        "# Exercise 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:27.812721Z",
          "start_time": "2023-12-18T15:27:27.340949Z"
        },
        "tags": [],
        "id": "8Ssla2HrZYuC"
      },
      "outputs": [],
      "source": [
        "# Imports and basic setup\n",
        "### UNCOMMENT THE CORRECT ONE\n",
        "# If you are using Jupyter Lab\n",
        "%matplotlib inline\n",
        "\n",
        "# If you are using Jupyter Notebook\n",
        "# %matplotlib notebook\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.max_open_warning': 40})\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.signal\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyCow-97ZYuD"
      },
      "source": [
        "# Comparing PVC and healthy peaks\n",
        "\n",
        "Last exercise we calculated a wide set of features on a sample ECG recording.\n",
        "In this exercise, we want to use these features to build a classifier that can separate healthy from PVC (premature ventricular contraction) heart beats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbHRw02gZYuD"
      },
      "source": [
        "## Ex 12.1: Data Cleaning\n",
        "We are going to use the [MIT ECG database](https://physionet.org/content/mitdb/1.0.0/), which was mentioned multiple times in the lecture, for this analysis.\n",
        "You can find a formatted and structured version of the DB in the `data` folder.\n",
        "The files have the following structure:\n",
        "\n",
        "- {patient_id}.csv -> The ECG recording\n",
        "- {patient_id}_all.csv -> The position of the R-peaks of all heart beats (PVC or normal). All heart beats that show a different condition than PVC are already excluded\n",
        "- {patient_id}_pvc.csv -> The position of all PVC heart beats in the recording.\n",
        "\n",
        "Not all patients in the database have PVC heart beats in the recordings.\n",
        "\n",
        "a) Find all patients that have PVC heart beats **and** normal beats\n",
        "\n",
        "b) Create a label vector for each patient. This should consist of a 2 column dataframe. The first column should be the position of the R-peak and the second should either be `\"PVC\"` or `\"N\"`, indicating a healthy or pathological beat.\n",
        "\n",
        "c) Count how many PVC vs. normal heart beats exist for these filtered patients\n",
        "\n",
        "d) Based on your findings, describe potential issues a classification using this data could have."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rMsxYXvRjzAn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:27.817496Z",
          "start_time": "2023-12-18T15:27:27.814383Z"
        },
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3e5b08b8aa1025da9a5be55b0d9a0a85",
          "grade": false,
          "grade_id": "pvc-ids",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "id": "AaAZWeoDZYuD"
      },
      "outputs": [],
      "source": [
        "# A) Work on the pvc_ids function to obtain all the patient ids that contain PVC beats\n",
        "\n",
        "\n",
        "\n",
        "def pvc_ids():\n",
        "    \"\"\"Function that obtains the ids of all patients in the data folder\n",
        "    that have both PVC and normal heartbeats in their data\n",
        "\n",
        "    Returns:\n",
        "        patients_with_pvc: A numpy array with the ids (integers) of all patients\n",
        "        that have both PVC and normal heartbeats in their data\n",
        "    \"\"\"\n",
        "    data = Path('./data')\n",
        "    patients_with_pvc = []\n",
        "\n",
        "    for file in data.glob('*_all.csv'):\n",
        "        patient_id = int(file.stem.split('_')[0])\n",
        "        pos_r = (pd.read_csv(file))['R'].values\n",
        "        pos_pvc = (pd.read_csv(data / f'{patient_id}_pvc.csv'))['PVC'].values\n",
        "\n",
        "        #result = np.all(np.isin(pos_pvc, pos_r))\n",
        "        if len(pos_pvc) != 0 and np.array_equal(pos_r, pos_pvc) == False:\n",
        "            patients_with_pvc.append(patient_id)\n",
        "\n",
        "    return patients_with_pvc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:27.893560Z",
          "start_time": "2023-12-18T15:27:27.817395Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3eb58198fcd0a1871a29cdc86108cb44",
          "grade": true,
          "grade_id": "pvc-ids-tests",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "zjCq6qpXZYuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83f2c43-0fa2-465c-9b49-bc7ea6e2dda6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100 102 104 105 106 108 114 116 119 121 123 200 201 202 203 205 208 209\n",
            " 210 213 215 217 219 221 223 228 230 231 233 234]\n",
            "\n",
            "\n",
            "\t\tPreliminary Tests Passed :)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##### DO NOT MODIFY THE LINES OF CODE IN THIS BLOCK\n",
        "#Run Test your pvc_ids function\n",
        "\n",
        "#Remember that the output of pvc_ids has to be a numpy array of integers\n",
        "### BEGIN TESTS\n",
        "patients_with_pvc= np.sort(pvc_ids())\n",
        "print(patients_with_pvc)\n",
        "\n",
        "\n",
        "assert patients_with_pvc.size==30,f\"You function is not working properly, you are missing or lacking one or more patients\"\n",
        "assert not (101 in patients_with_pvc),f\"You have selected a patient that does not fulfill the criteria. Some patients only have PVC heartbeats and no normal ones\"\n",
        "assert not (220 in patients_with_pvc),f\"You have selected a patient that does not fulfill the criteria. Some patients only have PVC heartbeats and no normal ones\"\n",
        "assert patients_with_pvc[3] == 105, f\"You function is not working properly, a value in your array seems to be incorrect\"\n",
        "assert patients_with_pvc[7] == 116, f\"You function is not working properly, a value in your array seems to be incorrect\"\n",
        "assert patients_with_pvc[24] == 223, f\"You function is not working properly, a value in your array seems to be incorrect\"\n",
        "\n",
        "print(\"\\n\\n\\t\\tPreliminary Tests Passed :)\\n\\n\")\n",
        "### END TESTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:27.898121Z",
          "start_time": "2023-12-18T15:27:27.895411Z"
        },
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "076f3c10ada59b15cf62be4171d3efeb",
          "grade": false,
          "grade_id": "label-vectors",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "id": "PKSHuHZ9ZYuD"
      },
      "outputs": [],
      "source": [
        "#B) Create label vectors\n",
        "def create_label_vectors():\n",
        "    \"\"\"Function that labels the R peaks of patients. The order should include the id of the patient first,\n",
        "    followed by the index location of the R peak and finally the label of the peak.\n",
        "\n",
        "    Returns:\n",
        "        all_beat_labels: A dataframe with 3 rows with the headers for patient_id , R peaks and heartbeat labels, which contains\n",
        "        the information of all heartbeats and classifies them either as normal (\"N\") or PVC (\"PVC\")\n",
        "\n",
        "        Example output (YOU HAVE TO COPY THE EXACT FORMAT FOR THE AUTOMATIC GRADING TO WORK):\n",
        "         patient_id     R      label\n",
        "0        100            77     N\n",
        "1        100            370    N\n",
        "2        100            662    N\n",
        "3        100            946    N\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        "55       100           32675   PVC\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    data_path = Path('./data')\n",
        "\n",
        "    patient_ids = []\n",
        "    for file in data_path.glob('*_all.csv'):\n",
        "        id = int(file.stem.split('_')[0])\n",
        "        patient_ids.append(int(id))\n",
        "\n",
        "    patient_ids.sort()\n",
        "\n",
        "    index = []\n",
        "    data = {\n",
        "        'patient_id': [],\n",
        "        'R': [],\n",
        "        'label': []\n",
        "    }\n",
        "\n",
        "    i = 0\n",
        "    for id in patient_ids:\n",
        "\n",
        "        pos_r = (pd.read_csv(data_path / f'{id}_all.csv'))['R'].values\n",
        "        pos_pvc = (pd.read_csv(data_path / f'{id}_pvc.csv'))['PVC'].values\n",
        "\n",
        "        if len(pos_pvc) == 0 or np.array_equal(pos_r, pos_pvc) == True:\n",
        "            continue\n",
        "\n",
        "        pos_pvc = set(pos_pvc)\n",
        "\n",
        "        for r_idx in pos_r:\n",
        "            index.append(i)\n",
        "            data['patient_id'].append(id)\n",
        "            data['R'].append(r_idx)\n",
        "            if r_idx in pos_pvc:\n",
        "                data['label'].append('PVC')\n",
        "            else:\n",
        "                data['label'].append('N')\n",
        "            i += 1\n",
        "\n",
        "    all_beat_labels = pd.DataFrame(data, index=index)\n",
        "    print(all_beat_labels.size)\n",
        "    return all_beat_labels\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:28.046409Z",
          "start_time": "2023-12-18T15:27:27.900300Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c4c568bc9aea615e6fe416beafd80226",
          "grade": true,
          "grade_id": "label-vectors-test",
          "locked": true,
          "points": 6,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "mUDilGm5ZYuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa4118d-f249-411b-dfd1-98295db9eb94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187470\n",
            "   patient_id     R label\n",
            "0         100    77     N\n",
            "1         100   370     N\n",
            "2         100   662     N\n",
            "3         100   946     N\n",
            "4         100  1231     N\n",
            "187470\n",
            "\n",
            "\n",
            "\t\tPreliminary Tests Passed :)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##### DO NOT MODIFY THE LINES OF CODE IN THIS BLOCK\n",
        "#Test your create_label_vectors function\n",
        "\n",
        "#REMEMBER TO USE THE FORMAT GIVEN IN EXAMPLE OUTPUT (even the header names)\n",
        "\n",
        "### BEGIN TESTS\n",
        "all_beat_labels = create_label_vectors()\n",
        "\n",
        "print(all_beat_labels.head(5))\n",
        "print(all_beat_labels.size)\n",
        "\n",
        "assert all_beat_labels.size==187470, f\"There is something wrong in your function, the size of the dataframe does not match the solution\"\n",
        "assert all_beat_labels.loc[4][\"R\"]== 1231,f\"There is something wrong in your function, there is a value mismatch with the correct answer\"\n",
        "assert all_beat_labels.loc[499][\"R\"]== 145111,f\"There is something wrong in your function, there is a value mismatch with the correct answer\"\n",
        "assert all_beat_labels.loc[4999][\"patient_id\"]== 105,f\"There is something wrong in your function, there is a value mismatch with the correct answer\"\n",
        "assert all_beat_labels.loc[62488][\"patient_id\"]== 234,f\"There is something wrong in your function, there is a value mismatch with the correct answer\"\n",
        "assert all_beat_labels.loc[3195][\"label\"]== \"N\",f\"There is something wrong in your function, there is a value mismatch with the correct answer\"\n",
        "assert all_beat_labels.loc[31915][\"label\"]== \"N\",f\"There is something wrong in your function, there is a value mismatch with the correct answer\"\n",
        "assert all_beat_labels.loc[2339][\"label\"]== \"PVC\",f\"There is something wrong in your function, there is a value mismatch with the correct answer\"\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\t\\tPreliminary Tests Passed :)\\n\\n\")\n",
        "### END TESTS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:28.050441Z",
          "start_time": "2023-12-18T15:27:28.047434Z"
        },
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d7a3c54f1892939d89901463ad47cf5d",
          "grade": false,
          "grade_id": "Heartbeat-count",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "id": "sYsl_BKPZYuD"
      },
      "outputs": [],
      "source": [
        "#C)  Count PVC vs non PVC heartbeats\n",
        "def count_heartbeats(all_beat_labels):\n",
        "    \"\"\"Function that obtains the count number of normal and PVC heartbeats for all patients\n",
        "\n",
        "    Arguments: all_beat_labels: A dataframe with the same format as the previous task b)\n",
        "\n",
        "    Returns:\n",
        "        N: The total number of normal Heartbeats within the dataframe\n",
        "        PVC: The total number of PVC Heartbeats within the dataframe\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    label_counts = all_beat_labels['label'].value_counts()\n",
        "\n",
        "    N = label_counts.get('N', 0)\n",
        "    PVC = label_counts.get('PVC', 0)\n",
        "\n",
        "    return N, PVC\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:28.059702Z",
          "start_time": "2023-12-18T15:27:28.053353Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c9a97f319ac00767ca7b14ae0e1fbf5f",
          "grade": true,
          "grade_id": "Heartbeat-count-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "1vKyeagJZYuE",
        "outputId": "3bf9a4ec-9946-45ff-d4ba-a433ba371742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Heartbeats:  55882 \n",
            "PVC Heartbeats:  6608\n",
            "\n",
            "\n",
            "\t\tPreliminary Tests Passed :)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##### DO NOT MODIFY THE LINES OF CODE IN THIS BLOCK\n",
        "##Run this cell to check your count_heartbeats function implementation\n",
        "#Remeber that there are hidden tests, so don't just create a function that delivers the values in the assert ;)\n",
        "\n",
        "### BEGIN TESTS\n",
        "N, PVC =  count_heartbeats(all_beat_labels)\n",
        "print(\"Normal Heartbeats: \",N,\"\\nPVC Heartbeats: \",PVC)\n",
        "\n",
        "assert N == 55882,f\"Your function is not counting the heartbeats properly\"\n",
        "assert PVC== 6608,f\"Your function is not counting the heartbeats properly\"\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\t\\tPreliminary Tests Passed :)\\n\\n\")\n",
        "### END TESTS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jjQ1joSZYuE"
      },
      "source": [
        "## Ex. 12.2: Calculating features\n",
        "\n",
        "As we learned in the lecture, we need to reduce the dimensionality of our data by calculating features for each heartbeat.\n",
        "\n",
        "a) Using the code from last exercise, extract all heartbeats from the selected patients.\n",
        "\n",
        "b) Calculate all features from last exercise for all heart beats. Use the first **healthy** heart beat of each patient for the template feature.\n",
        "\n",
        "c) Calculate a set of “generic” features for each heart beat: *mean*, *std*, *minimum*, *maximum*\n",
        "\n",
        "d) Compose all features into one matrix, where each row belongs to one heartbeat. Create a single matrix/`pd.DataFrame` combining all patients.\n",
        "Also like in the last exercise, before calculating the features utilize a 3-50 Hz fifth order Butterworth Bandpass filter on the ECG signal of each patient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:28.064042Z",
          "start_time": "2023-12-18T15:27:28.062234Z"
        },
        "tags": [],
        "id": "obklj88zZYuE"
      },
      "outputs": [],
      "source": [
        "# Helper funcs from last exercise\n",
        "def extract_qrst_complexes(signal, r_peaks, sampling_rate=360):\n",
        "    \"\"\"Extract all qrst complexes from a continous signal.\n",
        "\n",
        "    Cuts out a region of -50ms to 300ms around each provided R-peak\n",
        "\n",
        "    Args:\n",
        "        signal: np.array of ecg signal\n",
        "        r_peaks: list of indices indicating the postion of R-peaks in the signal\n",
        "        sampling_rate: Ssampling rate of the recording\n",
        "\n",
        "    Returns:\n",
        "        qrst: np.array with fixed number of culumns and one qrst complex per row\n",
        "    \"\"\"\n",
        "    signal = np.array(signal)\n",
        "    start = r_peaks - int(50 / 1000 * sampling_rate)\n",
        "    end = r_peaks + int(300 / 1000 * sampling_rate)\n",
        "\n",
        "    qrst = []\n",
        "    for s, e in zip(start, end):\n",
        "        qrst.append(signal[s:e])\n",
        "    qrst = np.array(qrst)\n",
        "    return qrst\n",
        "\n",
        "def find_q_peak(qrst, sampling_rate=360):\n",
        "    \"\"\"Find the Q peak in an array of qrst complexes extracted before.\n",
        "\n",
        "    The Q peak is the first valley to the left of the R-Peak\n",
        "\n",
        "    Returns:\n",
        "        The relative distance from the R-Peak in samples\n",
        "    \"\"\"\n",
        "    r_peak_pos = int(50/1000 * sampling_rate)\n",
        "    index_q = np.argmin(qrst[:, :r_peak_pos], axis=-1)\n",
        "    index_q = r_peak_pos - index_q\n",
        "    return index_q\n",
        "\n",
        "def find_s_peak(qrst, sampling_rate=360):\n",
        "    \"\"\"Find the S peak in an array of qrst complexes extracted before.\n",
        "\n",
        "    The S peak is the first valley to the right of the R-Peak\n",
        "\n",
        "    Returns:\n",
        "        The relative distance from the R-Peak in samples\n",
        "    \"\"\"\n",
        "    r_peak_pos = int(50/1000 * sampling_rate)\n",
        "    # Search 80ms to the right of the r_peak\n",
        "    search_index = int(80/1000 * sampling_rate)\n",
        "\n",
        "    index_s = np.argmin(qrst[:, r_peak_pos: r_peak_pos + search_index], axis=-1)\n",
        "    index_s = index_s\n",
        "    return index_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:28.095373Z",
          "start_time": "2023-12-18T15:27:28.064154Z"
        },
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95e1319de09c868864324482ffe18578",
          "grade": false,
          "grade_id": "patient-features-calc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "id": "_lAXv0E2ZYuE"
      },
      "outputs": [],
      "source": [
        "# Functions for task b)\n",
        "\n",
        "def qrs_width_calc(peaks,sampling_rate=360):\n",
        "    \"\"\"Extract the QRS width for a given ECG signal and its peaks\n",
        "\n",
        "    Args:\n",
        "        signal: np.array of ecg signal\n",
        "        peaks: pd.DataFrame with columns called \"R\",\"Q\" and \"S\" containing the position of all R-, Q- and S-peaks respectively\n",
        "        sampling_rate: Sampling rate of the recording\n",
        "\n",
        "    Returns:\n",
        "        QRS_Width: Array with the information of all the QRS widths (in seconds)\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    QRS_Width = (peaks['S'] - peaks['Q']) / sampling_rate\n",
        "\n",
        "    return QRS_Width\n",
        "\n",
        "def qr_amplitude_calc(signal,peaks):\n",
        "    \"\"\"Extract the QR Amplitude for a given ECG signal and its peaks\n",
        "\n",
        "    Args:\n",
        "        signal: np.array of ecg signal\n",
        "        peaks: pd.DataFrame with columns called \"R\",\"Q\" and \"S\" containing the position of all R-, Q- and S-peaks respectively\n",
        "        sampling_rate: Sampling rate of the recording\n",
        "\n",
        "    Returns:\n",
        "        QR_Amplitude: Float Array with the information of all the QR Amplitudes\n",
        "    \"\"\"\n",
        "    # Calculate the amplitude difference between the R-peak and the Q-valey\n",
        "    # YOUR CODE HERE\n",
        "    QR_Amplitude = (signal.values[peaks['R'].values]) - (signal.values[peaks['Q'].values])\n",
        "\n",
        "    return QR_Amplitude\n",
        "\n",
        "def rs_amplitude_calc(signal,peaks):\n",
        "    \"\"\"Extract the RS Amplitude for a given ECG signal and its peaks\n",
        "\n",
        "    Args:\n",
        "        signal: np.array of ecg signal\n",
        "        peaks: pd.DataFrame with columns called \"R\",\"Q\" and \"S\" containing the position of all R-, Q- and S-peaks respectively\n",
        "        sampling_rate: Sampling rate of the recording\n",
        "\n",
        "    Returns:\n",
        "        QR_Amplitude: Float Array with the information of all the RS Amplitudes\n",
        "    \"\"\"\n",
        "    # Calculate the amplitude difference between the R-peak and the S-valey\n",
        "    # YOUR CODE HERE\n",
        "    RS_Amplitude = (signal.values[peaks['R'].values]) - (signal.values[peaks['S'].values])\n",
        "\n",
        "    return RS_Amplitude\n",
        "\n",
        "\n",
        "def qrst_area_calc(qrst_complexes):\n",
        "    \"\"\"Extract the QRST area for a given ECG signal and its peaks\n",
        "\n",
        "    Args:\n",
        "        qrst_complexes: np.array with fixed number of columns and one qrst complex per row\n",
        "\n",
        "    Returns:\n",
        "        QRST_Area: Float Array with the information of all the QRST areas\n",
        "    \"\"\"\n",
        "    # Calculate the area under each QRST complex after substracting the mean value of each complex to normalize the baseline\n",
        "    # YOUR CODE HERE\n",
        "    QRST_Area = np.abs(qrst_complexes - qrst_complexes.mean(axis=1)[:, np.newaxis]).sum(axis=1)\n",
        "\n",
        "    return QRST_Area\n",
        "\n",
        "def template_calc(qrst_complexes,labels):\n",
        "    \"\"\"Extract the first QRS template for a given qrst complexes array\n",
        "\n",
        "    Args:\n",
        "        qrst_complexes: np.array with fixed number of columns and one qrst complex per row\n",
        "\n",
        "    Returns:\n",
        "        Template: First healthy QRS complex\n",
        "    \"\"\"\n",
        "    # Find the first \"normal QRS\" complex\n",
        "    # Assume the first peak in the series is a normal QRST complex\n",
        "    # Substract the baseline (minimum) from every qrst complex and then calculate the normalised dot-product\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    template = qrst_complexes[0] - qrst_complexes[0].min()\n",
        "    normalized_qrst = qrst_complexes - qrst_complexes.min(axis=1)[:, np.newaxis]\n",
        "\n",
        "    Template = (\n",
        "        np.sum(normalized_qrst * template, axis=1) /\n",
        "        (np.sqrt(np.sum(normalized_qrst**2, axis=1)) * np.sqrt(np.sum(template**2)))\n",
        "    )\n",
        "\n",
        "    return Template\n",
        "\n",
        "# Function for task c)\n",
        "def generic_features_calc(qrst_complexes):\n",
        "    \"\"\"Extract the generic information of the QRSt complexes to use as features\n",
        "\n",
        "    Args:\n",
        "        qrst_complexes: np.array with fixed number of columns and one qrst complex per row\n",
        "\n",
        "    Returns:\n",
        "        Mean: The mean value of the QRST complexes\n",
        "        Std:  The standard deviation value of the QRST complexes\n",
        "        Min:  The minimum value of the QRST complexes\n",
        "        Max:  The maximum value of the QRST complexes\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    Mean = qrst_complexes.mean(axis=1)\n",
        "    Std = qrst_complexes.std(axis=1)\n",
        "    Min = qrst_complexes.min(axis=1)\n",
        "    Max = qrst_complexes.max(axis=1)\n",
        "\n",
        "    return Mean, Std, Min, Max\n",
        "\n",
        "\n",
        "def calc_all_features_for_patient(signal, peaks, labels):\n",
        "    \"\"\"Extract all heartbeats and calc all features for a patient.\n",
        "\n",
        "    Args:\n",
        "        signal: np.array of ecg signal\n",
        "        peaks: pd.DataFrame with a column called \"R\" containing the position of all R-peaks\n",
        "        labels: array with either \"N\" or \"PVC\" for each r-peak\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with 1 column per feature and 1 column for the label\n",
        "    \"\"\"\n",
        "    peaks = peaks.copy()\n",
        "    # Remove peaks that are too close to the beginning or end of the dataset\n",
        "    peaks = peaks[peaks['R'].between(20, len(signal) - 110)]\n",
        "\n",
        "    # Extract the individual complexeses and important events withing the complex\n",
        "    qrst_complexes = extract_qrst_complexes(signal, peaks['R'], sampling_rate=360)\n",
        "    peaks['Q'] = peaks['R'] - find_q_peak(qrst_complexes)\n",
        "    peaks['S'] = peaks['R'] + find_s_peak(qrst_complexes)\n",
        "\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    # Calculate all features from last week\n",
        "\n",
        "    # QRS Width\n",
        "    features['QRS_Width'] = qrs_width_calc(peaks,sampling_rate=360)\n",
        "\n",
        "    # QR Amplitude difference\n",
        "    features['QR_amplitude'] = qr_amplitude_calc(signal,peaks)\n",
        "\n",
        "    # RS Amplitude difference\n",
        "    features['RS_amplitude'] = rs_amplitude_calc(signal,peaks)\n",
        "\n",
        "    # QRST Area\n",
        "    features['QRST_area'] = qrst_area_calc(qrst_complexes)\n",
        "\n",
        "    # Template Match\n",
        "    features['Template'] = template_calc(qrst_complexes,labels)\n",
        "\n",
        "    # Calculate a set of generic features\n",
        "    features['Mean'],features['Std'],features['Min'], features['Max'] = generic_features_calc(qrst_complexes)\n",
        "\n",
        "    # Add the label column\n",
        "    features['label'] = labels\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:28.230034Z",
          "start_time": "2023-12-18T15:27:28.080268Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f4c4e2dfe7241122a7f51aacc11c537",
          "grade": true,
          "grade_id": "patient-features-calc-tests",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "IlIeyY5KZYuE",
        "outputId": "9e0a6ab8-9274-4bfb-831d-39b599d0ca84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\t\tBeginning tests\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tAll Preliminary Tests Passed :)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##### DO NOT MODIFY THE LINES OF CODE IN THIS BLOCK\n",
        "## Run this block to test all of your function implementations within calc_all_features_for_patient\n",
        "\n",
        "print(\"\\n\\n\\t\\tBeginning tests\\n\\n\")\n",
        "\n",
        "######################preliminary preparations#################################\n",
        "sampling_rate=360\n",
        "#Read patient file\n",
        "\n",
        "\n",
        "for patient in patients_with_pvc:\n",
        "    Test_signal = pd.read_csv('./data/{}.csv'.format(patient), index_col=0)['ecg']\n",
        "\n",
        "    Test_beats = all_beat_labels[all_beat_labels['patient_id'] == patient]\n",
        "    break\n",
        "\n",
        "#Get labels and peaks in the same format as the calc_all_features_for_patient function\n",
        "Test_labels = Test_beats['label']\n",
        "Test_peaks = Test_beats[['R']].copy()\n",
        "Test_peaks = Test_peaks[Test_peaks['R'].between(20, len(Test_signal) - 110)]\n",
        "\n",
        "\n",
        "# Extract the individual complexeses and important events withing the complex\n",
        "Test_complexes = extract_qrst_complexes(Test_signal, Test_peaks['R'])\n",
        "\n",
        "Test_peaks['Q'] = Test_peaks['R'] - find_q_peak(Test_complexes)\n",
        "Test_peaks['S'] = Test_peaks['R'] + find_s_peak(Test_complexes)\n",
        "\n",
        "#################### Begin non-hidden asserts###################################\n",
        "\n",
        "#Test QRS width\n",
        "QRS_Width = qrs_width_calc(Test_peaks,sampling_rate=360)\n",
        "\n",
        "assert np.max(QRS_Width)<1,f\"Your QRS Width calculator output does not match the size of the result, you probably forgot to give the output in seconds instead of samples\"\n",
        "assert QRS_Width.size == 2239,f\"Your QRS Width calculator output does not match the size of the result\"\n",
        "assert np.around(np.mean(QRS_Width),4)==0.0457,f\"Your QRS Width calculator output does not match the correct result\"\n",
        "\n",
        "\n",
        "#Test QR amplitude\n",
        "QR_Amplitude = qr_amplitude_calc(Test_signal,Test_peaks)\n",
        "\n",
        "assert QR_Amplitude.size == 2239,f\"Your QR Amplitude calculator output does not match the size of the result\"\n",
        "assert np.around(np.mean(QR_Amplitude),4)==1.5213,f\"Your QR Amplitude calculator output does not match the correct result\"\n",
        "\n",
        "#Test RS amplitude\n",
        "RS_Amplitude = rs_amplitude_calc(Test_signal,Test_peaks)\n",
        "\n",
        "assert RS_Amplitude.size == 2239,f\"Your RS Amplitude calculator output does not match the size of the result\"\n",
        "assert np.around(np.mean(RS_Amplitude),4)==1.4566,f\"Your RS Amplitude calculator output does not match the correct result\"\n",
        "\n",
        "#Test QRST AREA\n",
        "QRST_Area = qrst_area_calc(Test_complexes)\n",
        "\n",
        "assert QRST_Area.size == 2239,f\"Your QR Amplitude calculator output does not match the size of the result\"\n",
        "assert np.around(np.mean(QRST_Area),4)==17.24,f\"Your QRST Area calculator output does not match the correct result\"\n",
        "\n",
        "#Test Template\n",
        "Template = template_calc(Test_complexes,Test_labels)\n",
        "\n",
        "assert Template.size == 2239,f\"Your QR Amplitude calculator output does not match the size of the result\"\n",
        "assert np.trunc(Template[0]) ==1,f\"Your Template calculator output is incorrect, the first heartbeat is the template and thus should perfectly match the template (have a value of 1)\"\n",
        "RestTest = Template[1:]\n",
        "assert np.max(RestTest)<1,f\"Your Template calculator output is incorrect, no heartbeat after the first one should match the template perfectly (they should have a value lower than 1)\"\n",
        "assert np.trunc(Template[0]) ==1,f\"Your Template calculator output is incorrect, the first heartbeat is the template and thus should perfectly match the template (have a value of 1)\"\n",
        "assert np.around(np.mean(Template),4)==0.9836,f\"Your QRST Area calculator output does not match the correct result\"\n",
        "\n",
        "#Test Generic features\n",
        "Mean1, Std1, Min1, Max1 = generic_features_calc(Test_complexes)\n",
        "\n",
        "assert (Mean1.size and Std1.size and Min1.size and Max1.size) == 2239,f\"Your Generic features do not match the size of the result\"\n",
        "assert np.around(np.mean(Mean1),4)==-0.3239,f\"Your calculated Mean does not match the correct result\"\n",
        "assert np.around(np.mean(Std1),4)==0.2718,f\"Your calculated standard deviation does not match the correct result\"\n",
        "assert np.around(np.mean(Min1),4)==-0.5604,f\"Your calculated Minimum does not match the correct result\"\n",
        "assert np.around(np.mean(Max1),4)==0.986,f\"Your calculated Maximum does not match the correct result\"\n",
        "\n",
        "print(\"\\n\\n\\t\\tAll Preliminary Tests Passed :)\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:28.287623Z",
          "start_time": "2023-12-18T15:27:28.224009Z"
        },
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "673e95da4a73e820754758d17e54fdda",
          "grade": false,
          "grade_id": "All-patients-features",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "id": "BbbCFkiHZYuE"
      },
      "outputs": [],
      "source": [
        "#Task d)\n",
        "\n",
        "sampling_rate = 360  # hz\n",
        "\n",
        "\n",
        "def All_Patients_Features():\n",
        "    \"\"\"\n",
        "    Use the previously programmed function calc_all_features_for_patient to obtain the features of all the heartbeats for all patients\n",
        "    Remember to also apply a 5th order Butterworth 3-50 Hz bandpass filter to each signal obtaining the peaks and features.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame with the heartbeat features of all patients with the columns given by the calc_all_features_for_patient output\n",
        "\n",
        "    Example Output for the first 2 elements:\n",
        "\n",
        "        QRS_Width \tQR_amplitude \tRS_amplitude \tQRST_area \tTemplate \tMean    \tStd     \tMin     \tMax     \tlabel\n",
        "    0 \t0.047222 \t1.304419    \t1.272772    \t12.740725 \t1.000000 \t0.007252 \t0.211623 \t-0.254819 \t1.049600 \tN\n",
        "    1 \t0.052778 \t1.473421    \t1.399725    \t16.753887 \t0.991165 \t0.009106 \t0.254250 \t-0.311316 \t1.162106 \tN\n",
        "\n",
        "    DUE TO GRADING PURPOSES, THE OUTPUT NEEDS TO PERFECTLY MATCH THIS FORMAT\n",
        "    \"\"\"\n",
        "    feature_all_patients = []\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    return feature_all_patients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:34.195615Z",
          "start_time": "2023-12-18T15:27:28.286400Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "91e27ce98ab128d1ce358e96ca219f60",
          "grade": true,
          "grade_id": "cell-cdbb95b9418db705",
          "locked": true,
          "points": 8,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "dpsWiql5ZYuE"
      },
      "outputs": [],
      "source": [
        "##### DO NOT MODIFY THE LINES OF CODE IN THIS BLOCK\n",
        "##Use this block to test your All patients Features function\n",
        "### BEGIN TESTS\n",
        "\n",
        "feature_all_patients = All_Patients_Features()\n",
        "print(feature_all_patients.head(651))\n",
        "\n",
        "print(np.around(feature_all_patients.loc[998][\"QRST_area\"],4))\n",
        "\n",
        "assert feature_all_patients.size==624830,f\"Your all_patients_features function is not working properly, the output size does not match the correct results\"\n",
        "assert np.around(feature_all_patients.loc[494][\"QRS_Width\"],4) ==0.0472 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[5925][\"QR_amplitude\"],4) ==1.344 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[19][\"RS_amplitude\"],4) ==1.3971 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[998][\"QRST_area\"],4) ==16.9264 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[339][\"Template\"],4) ==0.997 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[7736][\"Mean\"],4) ==0.0371 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[646][\"Std\"],4) ==0.2418 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[646][\"Min\"],4) ==-0.3075 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert np.around(feature_all_patients.loc[646][\"Max\"],4) ==1.1572 ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "assert feature_all_patients.loc[646][\"label\"] ==\"N\" ,f\"Your all_patients_features function output does not match the correct result, check the format or the way you calculated\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukC5dFnBZYuE"
      },
      "source": [
        "## Ex. 12.3: Feature Selection\n",
        "\n",
        "Now that we calculated a set of features it is important to check if they provide the separation we hoped.\n",
        "This is an important step, as our classifier can never be better than its data/features.\n",
        "If the features cannot separate our classes of interest, our classifier cannot magically achieve this.\n",
        "\n",
        "A typical way to do this, is to plot the histogram for each feature.\n",
        "\n",
        "a) Look at the visualisation below. Discuss what you would expect from a “good” feature.\n",
        "\n",
        "b) Pick the best 4 features you would consider as the best\n",
        "\n",
        "c) Explain the limitations of selecting features just based on a 1D histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:36.619974Z",
          "start_time": "2023-12-18T15:27:34.195877Z"
        },
        "tags": [],
        "id": "DNHEpj3aZYuF"
      },
      "outputs": [],
      "source": [
        "## Run this block too visualize the different feature histograms\n",
        "\n",
        "\n",
        "plot_longform_df = feature_all_patients.melt(['label'], value_name='value', var_name='features')\n",
        "g = sns.FacetGrid(plot_longform_df, col='features', hue=\"label\", sharex=False, sharey=False, col_wrap=3)\n",
        "g = (g.map(sns.kdeplot, 'value', fill=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MADYk18-ZYuF"
      },
      "source": [
        "## Ex. 12.4: Training a classifier\n",
        "\n",
        "With our set of features, we will now train a classifier.\n",
        "This is usually a crucial step, as the choice of classifier and and its parameters will heavily influence the final performance.\n",
        "While there are some rules of thumb, most of time this requires some trial and error or a proper grid search.\n",
        "\n",
        "For this exercise we are going to use a *RandomForestClassifier* (and leave all parameters at default), because it is simple to use and requires no further pre-processing of our features.\n",
        "Have a look at the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for further information.\n",
        "\n",
        "To test the performance of a classifier, we need to decide on a “Test Set”.\n",
        "A part of our data, we will not use to train the classifier, but only to evaluate its final performance.\n",
        "This is called a train-test-split and sklearn has some [helper functions](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for this.\n",
        "\n",
        "\n",
        "a) Use the documentation provided above to assemble a simple pipeline consisting of a train-test-split with 30% test data and stratification.\n",
        "\n",
        "b) Explain why “stratification” could be important for the given problem and name potential other issues of using a single train-test split like shown here.\n",
        "\n",
        "c) Train a Random Forest classifier using this train data and calculate the confusion matrix and the accuracy for this classification. Explain the meaning of each entry in the confusion matrix.\n",
        "\n",
        "d) See how the classification changes with all features (instead of just your selected features). Compare the results.\n",
        "\n",
        "\n",
        "**FYI: You have to use the random state number given in the code for the split and classifier, otherwise you won't be able to pass the test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:36.625043Z",
          "start_time": "2023-12-18T15:27:36.620777Z"
        },
        "tags": [],
        "id": "_yq_4in_ZYuF"
      },
      "outputs": [],
      "source": [
        "#Preliminary preparations before creating the classifier\n",
        "\n",
        "#For the next task we will work with the following 4 selected Features:\n",
        "\n",
        "selected_features = ['QRS_Width', 'Template', 'Min', 'Mean']\n",
        "\n",
        "#For reproducible results we will utilize the following random state:\n",
        "Random_state = 44 #Be sure to use it for both the split and the classifier sections\n",
        "\n",
        "\n",
        "# Features and label vector creation\n",
        "\n",
        "data = feature_all_patients[selected_features]\n",
        "labels = feature_all_patients['label']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:36.626218Z",
          "start_time": "2023-12-18T15:27:36.624315Z"
        },
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "53c94f093d4171df8dd56aedb53fd974",
          "grade": false,
          "grade_id": "data-split",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "id": "bxvCGjoSZYuF"
      },
      "outputs": [],
      "source": [
        "#a) Train and test data split\n",
        "from sklearn.model_selection import train_test_split ##Import required in this block for autograding purposes DO NOT REMOVE\n",
        "def data_split(data,labels):\n",
        "    \"\"\"Splits data into training and test data\n",
        "\n",
        "    Args:\n",
        "        data: pd.Dataframe containing the ECG selected features\n",
        "        labels: np.Array that contains the labels \"N\" or \"PVC\" for each of the heartbeats in the data\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_test, y_train, y_test: Data splits that follow the sklearn format\n",
        "    \"\"\"\n",
        "    # Remember: Use 44 for the random state parameter and  a 30% division for the data stratification\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:36.734024Z",
          "start_time": "2023-12-18T15:27:36.627815Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "72ae7d4f0cdfe43e5ac39f249c380f1c",
          "grade": true,
          "grade_id": "data-split-test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "yxaGmLUaZYuF"
      },
      "outputs": [],
      "source": [
        "##### DO NOT MODIFY THE LINES OF CODE IN THIS BLOCK\n",
        "### BEGIN TESTS\n",
        "#Run this block to test your data_split implementation\n",
        "\n",
        "X_train, X_test, y_train, y_test = data_split(data,labels)\n",
        "\n",
        "\n",
        "assert X_train.size ==174952,f\"Your data split is not working properly\"\n",
        "assert X_test.size ==74980,f\"Your data split is not working properly\"\n",
        "assert y_train.size ==43738,f\"Your data split is not working properly\"\n",
        "assert y_test.size ==18745,f\"Your data split is not working properly\"\n",
        "### END TESTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:37.218852Z",
          "start_time": "2023-12-18T15:27:36.692392Z"
        },
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4d501db78253d9bd29ae09ad0914a0e0",
          "grade": false,
          "grade_id": "confusion-matrix",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [],
        "id": "HeRi7y7SZYuF"
      },
      "outputs": [],
      "source": [
        "#c) Random Forest classifier\n",
        "\n",
        "#Create a random forest classifier and fit it with the train data\n",
        "#Use it to classify the test data and obtain its corresponding confusion matrix and accuracy score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "def random_forest(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Creates a random forest classifier with sklearn and also returns its predicted accuracy and confusion matrix on the given data\n",
        "\n",
        "    Args:\n",
        "        X_train, X_test, y_train, y_test: Data splits that follow the sklearn format\n",
        "\n",
        "    Returns:\n",
        "        classifier: The random forest classifier object created by sklearn\n",
        "        cf_matrix: The confusion matrix obtained by your classifier when predicting on the test data\n",
        "        Accuracy: The accuracy obtained by your classifier when predicting on the test data\n",
        "    \"\"\"\n",
        "    # Remember: Use 44 for the random state parameter and leave the other parameters in their standard values\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    return classifier,cf_matrix,accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:45.782524Z",
          "start_time": "2023-12-18T15:27:37.221513Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3020822dda0fb5899e366e0f66f3113a",
          "grade": true,
          "grade_id": "confusion-matrix-test",
          "locked": true,
          "points": 6,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "E0RHaKk-ZYuF"
      },
      "outputs": [],
      "source": [
        "##### DO NOT MODIFY THE LINES OF CODE IN THIS BLOCK\n",
        "### RUN THIS BLOCK TO TEST YOUR random_forest implementation\n",
        "\n",
        "### BEGIN TESTS\n",
        "classifier,cf_matrix, accuracy = random_forest(X_train, X_test, y_train, y_test)\n",
        "print(\"Classifier's accuracy: \", accuracy)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,display_labels=['N', 'PVC'])\n",
        "disp.plot()\n",
        "plt.show()\n",
        "#plot_confusion_matrix(classifier, X_test, y_test, normalize='true');\n",
        "\n",
        "assert np.around(accuracy,4)==0.9898,f\"Your random forest implementation is not working properly (check your random state, selected features and data split)\"\n",
        "assert cf_matrix[0,0] == 16691,f\"Your random forest implementation is not working properly (check your random state, selected features and data split)\"\n",
        "print(\"\\n\\n\\t\\tPreliminary Test Passed :)\\n\\n\")\n",
        "### END TESTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-18T15:27:53.241832Z",
          "start_time": "2023-12-18T15:27:45.785394Z"
        },
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3e1b8f641c3cbded972bbd669cd60c22",
          "grade": true,
          "grade_id": "all-features-classification",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "dPlEmS9UZYuF"
      },
      "outputs": [],
      "source": [
        "#d) All features classifier\n",
        "# After passing the previous test block, run this to see how the classification changes with all features\n",
        "\n",
        "\n",
        "data2 = feature_all_patients.drop(['label'], axis=1)\n",
        "labels2 = feature_all_patients['label']\n",
        "X_train2, X_test2, y_train2, y_test2 = data_split(data2,labels2)\n",
        "\n",
        "classifier,cf_matrix, accuracy = random_forest(X_train2, X_test2, y_train2, y_test2)\n",
        "print(accuracy)\n",
        "print(cf_matrix)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,display_labels=['N', 'PVC'])\n",
        "disp.plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deZZkNNIZYuF"
      },
      "source": [
        "## Ex. 12.5: Discussing classifier performance\n",
        "\n",
        "a) Would you trust the classifier to make an automatic decision in a clinical environment?\n",
        "\n",
        "b) For which performance parameter would you try to optimize the classifier performance? (TP-rate or TN-rate?)\n",
        "\n",
        "c) What other issues do you see with the current system?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}